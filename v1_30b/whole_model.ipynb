{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c64c39-bf92-4453-8841-9873891604f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796b82fd-d64c-4782-be6b-cbb36e0fb1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:37<00:00,  6.25s/it]\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/home1/ohs/ongoing_proj/xtwice/cechallenge/v1_30b/pyllama/pyllama_data/30B\"\n",
    "pths = os.listdir(base_path)\n",
    "\n",
    "ckpt_lst = []\n",
    "\n",
    "for pth in tqdm(pths):\n",
    "    if \"consolidated\" in pth:\n",
    "        ckpt_path = os.path.join(base_path, pth)\n",
    "        ckpt_lst.append(torch.load(ckpt_path, map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0550c41f-11b3-41ee-8d3c-fcf7f24916e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "keys_lst = []\n",
    "for i, ckpt in enumerate(ckpt_lst):\n",
    "    keys_lst.append(list(ckpt.keys()))\n",
    "print(len(keys_lst))\n",
    "\n",
    "for i, keys in enumerate(keys_lst):\n",
    "    for j, key_ in enumerate(keys):\n",
    "        for k, keys_ in enumerate(keys_lst):\n",
    "            if key_ not in keys_:\n",
    "                print(i, j, k, key_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0308bc24-f579-4338-b41c-ab39dbbf4342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_colpar(str):\n",
    "    column_parallel_name_lst = [\"output\", \"wq\", \"wk\", \"wv\", \"w1\", \"w3\"]\n",
    "    for colpar_name in column_parallel_name_lst:\n",
    "        if colpar_name in str:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_rowpar(str):\n",
    "    row_parallel_name_lst = [\"embeddings\", \"wo\", \"w2\"]\n",
    "    for rowpar_name in row_parallel_name_lst:\n",
    "        if rowpar_name in str:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_nopar(str):\n",
    "    no_parallel_name_lst = [\"rope\", \"norm\"]\n",
    "    for nopar_name in no_parallel_name_lst:\n",
    "        if nopar_name in str:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643240b0-45b0-4e87-814d-71b70fcfd85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 544/544 [00:27<00:00, 19.82it/s]\n"
     ]
    }
   ],
   "source": [
    "model_weights_dict = {}\n",
    "for i, model_weights_name in enumerate(tqdm(keys_lst[0])):\n",
    "    \n",
    "    a = None\n",
    "    for j in range(3):\n",
    "        \n",
    "        if a is None:\n",
    "            if check_colpar(model_weights_name):\n",
    "                a = torch.concat((ckpt_lst[j][model_weights_name],\n",
    "                                  ckpt_lst[j+1][model_weights_name]), dim=0)\n",
    "            elif check_rowpar(model_weights_name):\n",
    "                a = torch.concat((ckpt_lst[j][model_weights_name],\n",
    "                                  ckpt_lst[j+1][model_weights_name]), dim=1)\n",
    "            elif check_nopar(model_weights_name):\n",
    "                a = ckpt_lst[j][model_weights_name]\n",
    "                break\n",
    "            else:\n",
    "                assert True, \"not matching\"\n",
    "        else:\n",
    "            if check_colpar(model_weights_name):\n",
    "                a = torch.concat((a,\n",
    "                                  ckpt_lst[j+1][model_weights_name]), dim=0)\n",
    "            elif check_rowpar(model_weights_name):\n",
    "                a = torch.concat((a,\n",
    "                                  ckpt_lst[j+1][model_weights_name]), dim=1)\n",
    "            else:\n",
    "                assert True, \"not matching\"\n",
    "    \n",
    "    model_weights_dict[model_weights_name] = a\n",
    "\n",
    "len(model_weights_dict)\n",
    "torch.save(model_weights_dict,\"./whole_llama1_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8196468-45bf-48b2-9569-56f0cefb9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "577d3e82-3584-4fa4-b93f-c1829cdb1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"whole_llama1_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12d04f51-6aaa-4f68-b5e3-95f5ec18744c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_embeddings.weight torch.Size([32000, 6656])\n",
      "norm.weight torch.Size([6656])\n",
      "output.weight torch.Size([32000, 6656])\n",
      "layers.0.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.0.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.0.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.0.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.0.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.0.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.0.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.0.attention_norm.weight torch.Size([6656])\n",
      "layers.0.ffn_norm.weight torch.Size([6656])\n",
      "layers.1.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.1.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.1.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.1.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.1.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.1.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.1.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.1.attention_norm.weight torch.Size([6656])\n",
      "layers.1.ffn_norm.weight torch.Size([6656])\n",
      "layers.2.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.2.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.2.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.2.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.2.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.2.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.2.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.2.attention_norm.weight torch.Size([6656])\n",
      "layers.2.ffn_norm.weight torch.Size([6656])\n",
      "layers.3.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.3.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.3.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.3.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.3.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.3.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.3.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.3.attention_norm.weight torch.Size([6656])\n",
      "layers.3.ffn_norm.weight torch.Size([6656])\n",
      "layers.4.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.4.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.4.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.4.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.4.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.4.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.4.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.4.attention_norm.weight torch.Size([6656])\n",
      "layers.4.ffn_norm.weight torch.Size([6656])\n",
      "layers.5.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.5.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.5.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.5.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.5.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.5.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.5.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.5.attention_norm.weight torch.Size([6656])\n",
      "layers.5.ffn_norm.weight torch.Size([6656])\n",
      "layers.6.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.6.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.6.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.6.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.6.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.6.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.6.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.6.attention_norm.weight torch.Size([6656])\n",
      "layers.6.ffn_norm.weight torch.Size([6656])\n",
      "layers.7.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.7.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.7.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.7.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.7.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.7.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.7.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.7.attention_norm.weight torch.Size([6656])\n",
      "layers.7.ffn_norm.weight torch.Size([6656])\n",
      "layers.8.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.8.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.8.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.8.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.8.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.8.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.8.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.8.attention_norm.weight torch.Size([6656])\n",
      "layers.8.ffn_norm.weight torch.Size([6656])\n",
      "layers.9.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.9.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.9.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.9.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.9.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.9.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.9.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.9.attention_norm.weight torch.Size([6656])\n",
      "layers.9.ffn_norm.weight torch.Size([6656])\n",
      "layers.10.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.10.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.10.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.10.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.10.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.10.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.10.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.10.attention_norm.weight torch.Size([6656])\n",
      "layers.10.ffn_norm.weight torch.Size([6656])\n",
      "layers.11.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.11.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.11.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.11.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.11.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.11.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.11.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.11.attention_norm.weight torch.Size([6656])\n",
      "layers.11.ffn_norm.weight torch.Size([6656])\n",
      "layers.12.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.12.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.12.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.12.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.12.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.12.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.12.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.12.attention_norm.weight torch.Size([6656])\n",
      "layers.12.ffn_norm.weight torch.Size([6656])\n",
      "layers.13.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.13.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.13.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.13.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.13.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.13.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.13.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.13.attention_norm.weight torch.Size([6656])\n",
      "layers.13.ffn_norm.weight torch.Size([6656])\n",
      "layers.14.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.14.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.14.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.14.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.14.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.14.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.14.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.14.attention_norm.weight torch.Size([6656])\n",
      "layers.14.ffn_norm.weight torch.Size([6656])\n",
      "layers.15.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.15.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.15.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.15.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.15.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.15.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.15.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.15.attention_norm.weight torch.Size([6656])\n",
      "layers.15.ffn_norm.weight torch.Size([6656])\n",
      "layers.16.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.16.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.16.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.16.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.16.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.16.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.16.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.16.attention_norm.weight torch.Size([6656])\n",
      "layers.16.ffn_norm.weight torch.Size([6656])\n",
      "layers.17.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.17.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.17.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.17.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.17.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.17.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.17.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.17.attention_norm.weight torch.Size([6656])\n",
      "layers.17.ffn_norm.weight torch.Size([6656])\n",
      "layers.18.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.18.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.18.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.18.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.18.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.18.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.18.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.18.attention_norm.weight torch.Size([6656])\n",
      "layers.18.ffn_norm.weight torch.Size([6656])\n",
      "layers.19.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.19.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.19.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.19.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.19.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.19.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.19.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.19.attention_norm.weight torch.Size([6656])\n",
      "layers.19.ffn_norm.weight torch.Size([6656])\n",
      "layers.20.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.20.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.20.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.20.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.20.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.20.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.20.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.20.attention_norm.weight torch.Size([6656])\n",
      "layers.20.ffn_norm.weight torch.Size([6656])\n",
      "layers.21.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.21.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.21.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.21.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.21.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.21.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.21.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.21.attention_norm.weight torch.Size([6656])\n",
      "layers.21.ffn_norm.weight torch.Size([6656])\n",
      "layers.22.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.22.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.22.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.22.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.22.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.22.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.22.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.22.attention_norm.weight torch.Size([6656])\n",
      "layers.22.ffn_norm.weight torch.Size([6656])\n",
      "layers.23.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.23.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.23.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.23.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.23.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.23.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.23.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.23.attention_norm.weight torch.Size([6656])\n",
      "layers.23.ffn_norm.weight torch.Size([6656])\n",
      "layers.24.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.24.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.24.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.24.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.24.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.24.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.24.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.24.attention_norm.weight torch.Size([6656])\n",
      "layers.24.ffn_norm.weight torch.Size([6656])\n",
      "layers.25.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.25.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.25.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.25.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.25.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.25.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.25.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.25.attention_norm.weight torch.Size([6656])\n",
      "layers.25.ffn_norm.weight torch.Size([6656])\n",
      "layers.26.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.26.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.26.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.26.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.26.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.26.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.26.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.26.attention_norm.weight torch.Size([6656])\n",
      "layers.26.ffn_norm.weight torch.Size([6656])\n",
      "layers.27.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.27.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.27.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.27.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.27.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.27.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.27.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.27.attention_norm.weight torch.Size([6656])\n",
      "layers.27.ffn_norm.weight torch.Size([6656])\n",
      "layers.28.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.28.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.28.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.28.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.28.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.28.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.28.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.28.attention_norm.weight torch.Size([6656])\n",
      "layers.28.ffn_norm.weight torch.Size([6656])\n",
      "layers.29.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.29.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.29.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.29.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.29.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.29.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.29.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.29.attention_norm.weight torch.Size([6656])\n",
      "layers.29.ffn_norm.weight torch.Size([6656])\n",
      "layers.30.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.30.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.30.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.30.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.30.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.30.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.30.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.30.attention_norm.weight torch.Size([6656])\n",
      "layers.30.ffn_norm.weight torch.Size([6656])\n",
      "layers.31.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.31.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.31.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.31.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.31.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.31.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.31.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.31.attention_norm.weight torch.Size([6656])\n",
      "layers.31.ffn_norm.weight torch.Size([6656])\n",
      "layers.32.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.32.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.32.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.32.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.32.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.32.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.32.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.32.attention_norm.weight torch.Size([6656])\n",
      "layers.32.ffn_norm.weight torch.Size([6656])\n",
      "layers.33.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.33.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.33.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.33.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.33.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.33.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.33.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.33.attention_norm.weight torch.Size([6656])\n",
      "layers.33.ffn_norm.weight torch.Size([6656])\n",
      "layers.34.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.34.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.34.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.34.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.34.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.34.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.34.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.34.attention_norm.weight torch.Size([6656])\n",
      "layers.34.ffn_norm.weight torch.Size([6656])\n",
      "layers.35.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.35.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.35.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.35.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.35.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.35.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.35.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.35.attention_norm.weight torch.Size([6656])\n",
      "layers.35.ffn_norm.weight torch.Size([6656])\n",
      "layers.36.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.36.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.36.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.36.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.36.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.36.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.36.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.36.attention_norm.weight torch.Size([6656])\n",
      "layers.36.ffn_norm.weight torch.Size([6656])\n",
      "layers.37.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.37.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.37.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.37.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.37.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.37.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.37.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.37.attention_norm.weight torch.Size([6656])\n",
      "layers.37.ffn_norm.weight torch.Size([6656])\n",
      "layers.38.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.38.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.38.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.38.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.38.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.38.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.38.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.38.attention_norm.weight torch.Size([6656])\n",
      "layers.38.ffn_norm.weight torch.Size([6656])\n",
      "layers.39.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.39.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.39.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.39.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.39.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.39.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.39.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.39.attention_norm.weight torch.Size([6656])\n",
      "layers.39.ffn_norm.weight torch.Size([6656])\n",
      "layers.40.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.40.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.40.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.40.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.40.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.40.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.40.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.40.attention_norm.weight torch.Size([6656])\n",
      "layers.40.ffn_norm.weight torch.Size([6656])\n",
      "layers.41.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.41.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.41.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.41.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.41.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.41.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.41.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.41.attention_norm.weight torch.Size([6656])\n",
      "layers.41.ffn_norm.weight torch.Size([6656])\n",
      "layers.42.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.42.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.42.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.42.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.42.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.42.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.42.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.42.attention_norm.weight torch.Size([6656])\n",
      "layers.42.ffn_norm.weight torch.Size([6656])\n",
      "layers.43.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.43.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.43.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.43.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.43.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.43.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.43.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.43.attention_norm.weight torch.Size([6656])\n",
      "layers.43.ffn_norm.weight torch.Size([6656])\n",
      "layers.44.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.44.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.44.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.44.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.44.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.44.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.44.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.44.attention_norm.weight torch.Size([6656])\n",
      "layers.44.ffn_norm.weight torch.Size([6656])\n",
      "layers.45.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.45.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.45.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.45.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.45.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.45.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.45.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.45.attention_norm.weight torch.Size([6656])\n",
      "layers.45.ffn_norm.weight torch.Size([6656])\n",
      "layers.46.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.46.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.46.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.46.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.46.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.46.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.46.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.46.attention_norm.weight torch.Size([6656])\n",
      "layers.46.ffn_norm.weight torch.Size([6656])\n",
      "layers.47.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.47.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.47.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.47.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.47.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.47.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.47.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.47.attention_norm.weight torch.Size([6656])\n",
      "layers.47.ffn_norm.weight torch.Size([6656])\n",
      "layers.48.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.48.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.48.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.48.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.48.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.48.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.48.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.48.attention_norm.weight torch.Size([6656])\n",
      "layers.48.ffn_norm.weight torch.Size([6656])\n",
      "layers.49.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.49.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.49.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.49.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.49.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.49.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.49.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.49.attention_norm.weight torch.Size([6656])\n",
      "layers.49.ffn_norm.weight torch.Size([6656])\n",
      "layers.50.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.50.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.50.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.50.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.50.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.50.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.50.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.50.attention_norm.weight torch.Size([6656])\n",
      "layers.50.ffn_norm.weight torch.Size([6656])\n",
      "layers.51.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.51.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.51.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.51.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.51.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.51.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.51.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.51.attention_norm.weight torch.Size([6656])\n",
      "layers.51.ffn_norm.weight torch.Size([6656])\n",
      "layers.52.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.52.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.52.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.52.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.52.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.52.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.52.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.52.attention_norm.weight torch.Size([6656])\n",
      "layers.52.ffn_norm.weight torch.Size([6656])\n",
      "layers.53.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.53.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.53.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.53.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.53.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.53.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.53.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.53.attention_norm.weight torch.Size([6656])\n",
      "layers.53.ffn_norm.weight torch.Size([6656])\n",
      "layers.54.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.54.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.54.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.54.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.54.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.54.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.54.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.54.attention_norm.weight torch.Size([6656])\n",
      "layers.54.ffn_norm.weight torch.Size([6656])\n",
      "layers.55.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.55.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.55.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.55.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.55.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.55.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.55.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.55.attention_norm.weight torch.Size([6656])\n",
      "layers.55.ffn_norm.weight torch.Size([6656])\n",
      "layers.56.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.56.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.56.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.56.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.56.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.56.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.56.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.56.attention_norm.weight torch.Size([6656])\n",
      "layers.56.ffn_norm.weight torch.Size([6656])\n",
      "layers.57.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.57.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.57.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.57.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.57.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.57.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.57.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.57.attention_norm.weight torch.Size([6656])\n",
      "layers.57.ffn_norm.weight torch.Size([6656])\n",
      "layers.58.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.58.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.58.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.58.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.58.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.58.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.58.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.58.attention_norm.weight torch.Size([6656])\n",
      "layers.58.ffn_norm.weight torch.Size([6656])\n",
      "layers.59.attention.wq.weight torch.Size([6656, 6656])\n",
      "layers.59.attention.wk.weight torch.Size([6656, 6656])\n",
      "layers.59.attention.wv.weight torch.Size([6656, 6656])\n",
      "layers.59.attention.wo.weight torch.Size([6656, 6656])\n",
      "layers.59.feed_forward.w1.weight torch.Size([17920, 6656])\n",
      "layers.59.feed_forward.w2.weight torch.Size([6656, 17920])\n",
      "layers.59.feed_forward.w3.weight torch.Size([17920, 6656])\n",
      "layers.59.attention_norm.weight torch.Size([6656])\n",
      "layers.59.ffn_norm.weight torch.Size([6656])\n",
      "rope.freqs torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for k,v in ckpt.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343d85c-3d59-48d1-9bb4-b197917748f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cechallenge",
   "language": "python",
   "name": "cechallenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
